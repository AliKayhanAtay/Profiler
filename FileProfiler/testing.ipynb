{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d2ea05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from extractor import get_text\n",
    "from scan import get_files\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from prompt import *\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb863445",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = r\"C:\\Users\\alika\\OneDrive\\Masaüstü\\Profiler\\FileProfiler\\test\\wiki_docs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e4043ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = Path(PATH)\n",
    "rows = []\n",
    "for f in directory.iterdir():\n",
    "    if f.is_file():\n",
    "        rows.append({\n",
    "        \"Full Path\": str(f.resolve()),\n",
    "        \"File Name\": f.stem,\n",
    "        \"Extension\": f.suffix.lstrip('.')\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(rows).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0268dd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = get_text(df['Full Path'][0])\n",
    "question = r'Is there any personal information in the document ?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f491c235",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1379f2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\"Authorization\": f\"Bearer {os.getenv(\"OPENROUTER_KEY\")}\",\n",
    "            \"Content-Type\": \"application/json\",}\n",
    "\n",
    "data = {\"model\": \"qwen/qwen3-8b\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": sp},\n",
    "                        {\"role\": \"user\", \"content\": up.format(text, question)}],}\n",
    "\n",
    "r = requests.post(os.getenv(\"OPENROUTER_URL\"),\n",
    "                headers=headers, data=json.dumps(data))\n",
    "if r.status_code==200:\n",
    "        resp = json.loads(r.text.strip())[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98450d87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n\"type\": \"Report\",\\n\"language\": \"English\",\\n\"answer\": \"No\",\\n\"reason\": \"The document discusses the 1939 SANFL season, its ladder, finals series, and grand final. It does not contain any personal data such as names, contact information, or identifying details of individuals.\"\\n}'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8f7d58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bc16ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03469322",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      1\u001b[39m messages = [\n\u001b[32m      2\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33msystem\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: sp},\n\u001b[32m      3\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m,   \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: up.format(text, question)},\n\u001b[32m      4\u001b[39m ]\n\u001b[32m      6\u001b[39m     \u001b[38;5;66;03m# Turn messages into a single generation prompt\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m chat_text = \u001b[43mtokenizer\u001b[49m.apply_chat_template(\n\u001b[32m      8\u001b[39m     messages,\n\u001b[32m      9\u001b[39m     tokenize=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     10\u001b[39m     add_generation_prompt=\u001b[38;5;28;01mTrue\u001b[39;00m,  \u001b[38;5;66;03m# adds assistant prefix\u001b[39;00m\n\u001b[32m     11\u001b[39m )\n\u001b[32m     13\u001b[39m inputs = tokenizer(chat_text, return_tensors=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m).to(device)\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n",
      "\u001b[31mNameError\u001b[39m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": sp},\n",
    "    {\"role\": \"user\",   \"content\": up.format(text, question)},\n",
    "]\n",
    "\n",
    "    # Turn messages into a single generation prompt\n",
    "chat_text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,  # adds assistant prefix\n",
    ")\n",
    "\n",
    "inputs = tokenizer(chat_text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output_ids = model.generate(\n",
    "        **inputs,\n",
    "        #max_new_tokens=32,\n",
    "        temperature=0.0,      # for deterministic/classification-like tasks\n",
    "        top_p=0.9,\n",
    "        do_sample=False,\n",
    "    )\n",
    "\n",
    "# gen_ids = output_ids[0, inputs[\"input_ids\"].shape[1]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc118f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_name = \"Qwen/Qwen3-8B\"  # or another Qwen*/Qwen3* instruct model\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f506cea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.57.1\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759c2852",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e3007d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b0c362f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out['content'] = df_out['out_js'].apply(lambda row: row['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c71800a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    {'type': 'Report', 'language': 'Turkish', 'ans...\n",
       "1    {'type': 'Report', 'language': 'Turkish', 'ans...\n",
       "2    {'type': 'Report', 'language': 'Turkish', 'ans...\n",
       "3    {'type': 'Report', 'language': 'Turkish', 'ans...\n",
       "4    {'type': 'Report', 'language': 'Turkish', 'ans...\n",
       "5    {'type': 'Report', 'language': 'Turkish', 'ans...\n",
       "6    {'type': 'Report', 'language': 'Turkish', 'ans...\n",
       "7    {'type': 'Report', 'language': 'Turkish', 'ans...\n",
       "8    {'type': 'Report', 'language': 'Turkish', 'ans...\n",
       "9    {'type': 'report', 'language': 'tr', 'answer':...\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out['content'] = df_out['content'].apply(lambda row: json.loads(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cadc81f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da52172",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ea830f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
